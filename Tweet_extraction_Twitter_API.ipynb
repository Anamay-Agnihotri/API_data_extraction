{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>  <h1>doLoop Tech</h1> <center>\n",
    "<center> <h1> Twitter REST API </h1> <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import keys      # contains personal credentials that identifies user [see example in `keys.py` file]\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "#pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import Twython, TwythonError # library for Twitter API wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(keys)\n",
    "keychain = keys.keychain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Getting credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init(keychain):\n",
    "    \"\"\" Dummy function to get credential details from keychain\n",
    "        \n",
    "        Parameters:\n",
    "          keychain: user keychain with private info\n",
    "    \n",
    "        Return Value: Needed credentials to access the Twitter API\n",
    "    \"\"\"\n",
    "    api_key = keychain['twitter']['api_key']\n",
    "    api_secret = keychain['twitter']['api_secret']\n",
    "    access_token = keychain['twitter']['access_token']\n",
    "    access_token_secret = keychain['twitter']['access_token_secret']\n",
    "    return (api_key,api_secret,access_token,access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accessing function definition\n",
    "#?init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def APIload(api_key,api_secret,access_token,access_token_s):\n",
    "    \"\"\" Takes authorization information and returns twython object\n",
    "        used for tweet extraction.\n",
    "        \n",
    "        Parameters:\n",
    "           api_key: Client key\n",
    "        api_secret: Client secret (keep hidden from application)\n",
    "      access_token: Access token from Twitter server\n",
    "    access_token_s: Token secret for server\n",
    "    \n",
    "        Return Value: Twython object\n",
    "    \"\"\"\n",
    "    auth = Twython(api_key,api_secret,access_token,access_token_s)\n",
    "    return auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key,secret,a_token,a_secret = init(keychain)\n",
    "Auth = APIload(key,secret,a_token,a_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Getting tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Parameter initialization and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = 'Twitter -filter:retweets' # see twitter documentation for more []\n",
    "text = []\n",
    "location = []\n",
    "date = []\n",
    "time = []\n",
    "file_top = 'Top_metadata:'+query+'.json'\n",
    "file_init = \"Init_metadata:\"+query+\".json\"\n",
    "file_bottom = 'Bottom_metadata:'+query+'.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLimit(auth):\n",
    "    \"\"\" Function to get count of remaining requests to the\n",
    "        twitter server.\n",
    "        \n",
    "        Parameters:\n",
    "          auth: twython authorization object\n",
    "    \n",
    "        Return Value: number of requests remaining to the server\n",
    "    \"\"\"\n",
    "    Limit = auth.get_lastfunction_header('x-rate-limit-remaining')\n",
    "    if Limit == None:\n",
    "        print(\"Rate limit error!\")\n",
    "    else:\n",
    "        return int(Limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_since_id(metadata):\n",
    "    \"\"\" Function to get since_id parameter from twython object.\n",
    "        Since_id is used to keep track of the top of the tweet\n",
    "        list which is needed to obtain newer incoming tweets.\n",
    "        \n",
    "        Parameters:\n",
    "          metadata: json containing the search metadata from\n",
    "                    previous server query\n",
    "                \n",
    "        Return Value: since_id parameter\n",
    "    \"\"\"\n",
    "    refresh_url = metadata['refresh_url']\n",
    "    pattern = r'\\?since_id=(\\d*)&'\n",
    "    regex = re.compile(pattern, re.S)\n",
    "    since_id = regex.search(refresh_url)\n",
    "    return(int(since_id[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_max_id(metadata):\n",
    "    \"\"\" Function to get max_id parameter from twython object.\n",
    "        Max_id is used to keep track of the bottom of the tweet\n",
    "        list which is needed to obtain the next batch of tweets.\n",
    "        \n",
    "        Parameters:\n",
    "          metadata: json containing the search metadata from\n",
    "                    previous server query\n",
    "    \n",
    "        Return Value: max_id parameter\n",
    "    \"\"\"\n",
    "    try:\n",
    "        next_results = metadata['next_results']\n",
    "        pattern = r'\\?max_id=(\\d*)&'\n",
    "        regex = re.compile(pattern, re.S)\n",
    "        max_id = regex.search(next_results)\n",
    "        return(int(max_id[1]))\n",
    "    except:\n",
    "        print(\"Result error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_once(f):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        if not wrapper.has_run:\n",
    "            wrapper.has_run = True\n",
    "            return f(*args, **kwargs)\n",
    "    wrapper.has_run = False\n",
    "    return wrapper\n",
    "\n",
    "@run_once\n",
    "def fornewquery(auth,query,text,location,date,time):\n",
    "    \"\"\" Function to get new tweets (max 100) since the first server\n",
    "        call in previous session for a particular query.\n",
    "        \n",
    "        Parameters:\n",
    "              auth: twython api object\n",
    "             query: search query\n",
    "              text: tweet text list to be appended\n",
    "          location: tweet location list to be appended\n",
    "              date: tweet date list to be appended\n",
    "              time: tweet time list to be appended\n",
    "    \n",
    "        Return Value: twython object with new tweets\n",
    "    \"\"\"\n",
    "    try:\n",
    "        object1 = auth.search(q=query,count=100,lang='en',tweet_mode='extended')\n",
    "        Limit = getLimit(auth)\n",
    "        print(\"Query successful. Requests remaining: \",Limit)\n",
    "    except TwythonError as e:\n",
    "        print(e)\n",
    "\n",
    "    for i in range(0,len(object1['statuses'])):\n",
    "        text.append(object1['statuses'][i]['full_text'])\n",
    "        location.append(object1['statuses'][i]['user']['location'])\n",
    "        date.append(object1['statuses'][i]['created_at'][4:10])\n",
    "        time.append(object1['statuses'][i]['created_at'][11:19])\n",
    "    file = \"Init_metadata:\"+query+\".json\"\n",
    "    with open(file, 'w') as outfile:\n",
    "        json.dump(object1['search_metadata'], outfile)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boom(auth,query,metadata,text,location,date,time):\n",
    "    \"\"\" Function to retrive tweets until server error or \n",
    "        rate-limit exceeded. Should retrieve approx 17000\n",
    "        tweets when fully functional (rate limit resets\n",
    "        every 15 mins).\n",
    "        \n",
    "        Note: Function keeps running till server timeout. \n",
    "              Make sure to use drop_duplicates() in Step 4\n",
    "              before loading into SQL db.\n",
    "        \n",
    "        Parameters:\n",
    "              auth: twython api object\n",
    "             query: search query\n",
    "          metadata: json containing the search metadata from\n",
    "                    previous server query\n",
    "              text: tweet text list to be appended\n",
    "          location: tweet location list to be appended\n",
    "              date: tweet date list to be appended\n",
    "              time: tweet time list to be appended\n",
    "    \n",
    "        Return Value: appended lists and last request object\n",
    "                      for further retrieval.\n",
    "    \"\"\"\n",
    "    file = 'Bottom_metadata:'+query+'.json'\n",
    "    try:\n",
    "        with open(file) as f:\n",
    "            metadata_end = json.load(f)\n",
    "    except:\n",
    "        print(\"Nothing to load from endpoint json.\")\n",
    "        pass\n",
    "        \n",
    "    Limit = getLimit(auth)\n",
    "    \n",
    "    try:\n",
    "        while Limit > 0:\n",
    "            Limit = getLimit(auth)\n",
    "            max_id = retrieve_max_id(metadata)\n",
    "            try:\n",
    "                object1 = auth.search(q=query,\n",
    "                                  count=100,lang='en',tweet_mode='extended',max_id=max_id)\n",
    "                metadata = object1['search_metadata']\n",
    "                print(\"Query successful. Requests remaining: \",Limit)\n",
    "            except Exception as ex:\n",
    "                template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "                message = template.format(type(ex).__name__, ex.args)\n",
    "                print(message)\n",
    "                pass\n",
    "            for j in range(0,len(object1['statuses'])):\n",
    "                text.append(object1['statuses'][j]['full_text'])\n",
    "                location.append(object1['statuses'][j]['user']['location'])\n",
    "                date.append(object1['statuses'][j]['created_at'][4:10])\n",
    "                time.append(object1['statuses'][j]['created_at'][11:19])\n",
    "            metadata_end = object1['search_metadata']\n",
    "    except TwythonError as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    print(\"Terminated.\")\n",
    "    \n",
    "    try:\n",
    "        with open(file, 'w') as outfile:\n",
    "            json.dump(metadata_end, outfile)\n",
    "    except Exception as ex:\n",
    "        template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "        message = template.format(type(ex).__name__, ex.args)\n",
    "        print(message) \n",
    "    return (metadata_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_tweets(auth,query,metadata,text,location,date,time):\n",
    "    \"\"\" Function to get all new tweets since initial server\n",
    "        call in previous session for a particular query.\n",
    "        \n",
    "        Parameters:\n",
    "              auth: twython api object\n",
    "             query: search query\n",
    "          metadata: json containing the search metadata from\n",
    "                    previous server query\n",
    "              text: tweet text list to be appended\n",
    "          location: tweet location list to be appended\n",
    "              date: tweet date list to be appended\n",
    "              time: tweet time list to be appended\n",
    "    \n",
    "        Return Value: twython object with new tweets\n",
    "    \"\"\"\n",
    "    file = 'Top_metadata:'+query+'.json'\n",
    "    since_id = retrieve_since_id(metadata) # can't initialize getLimit before call to the server\n",
    "    try:\n",
    "        latest = auth.search(q=query,count=100,lang='en',tweet_mode='extended',since_id=since_id)\n",
    "        Limit = getLimit(auth)\n",
    "        if len(latest['statuses'])==0:\n",
    "            print(\"No new results. Requests remaining: \",Limit)\n",
    "            \n",
    "        while len(latest['statuses'])>0:\n",
    "            Limit = getLimit(auth)\n",
    "            print(\"Query successful. Requests remaining: \",Limit)\n",
    "            for i in range(0,len(latest['statuses'])):\n",
    "                text.append(latest['statuses'][i]['full_text'])\n",
    "                location.append(latest['statuses'][i]['user']['location'])\n",
    "                date.append(latest['statuses'][i]['created_at'][4:10])\n",
    "                time.append(latest['statuses'][i]['created_at'][11:19])\n",
    "            since_id = retrieve_since_id(latest['search_metadata'])\n",
    "            latest = auth.search(q=query,count=100,lang='en',tweet_mode='extended',since_id=since_id)\n",
    "            \n",
    "        with open(file, 'w') as outfile:\n",
    "            json.dump(latest['search_metadata'], outfile)\n",
    "                \n",
    "        with open(file) as f:\n",
    "            metadata = json.load(f)\n",
    "        return(metadata)\n",
    "    except TwythonError as e:\n",
    "        print(e)\n",
    "        with open(file) as f:\n",
    "            metadata = json.load(f)\n",
    "        return(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The startpoint should only be called ONCE for each query.\n",
    "fornewquery(Auth,query,text,location,date,time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(file_init) as f:\n",
    "    startpoint_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(startpoint_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only for the first new call from startpoint\n",
    "top_metadata = get_new_tweets(Auth,query,startpoint_metadata,text,location,date,time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(file_top) as f:\n",
    "    top_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for all future calls for the query\n",
    "top_metadata = get_new_tweets(Auth,query,top_metadata,text,location,date,time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for first batch\n",
    "endpoint_metadata = boom(Auth,query,startpoint_metadata,text,location,date,time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(file_bottom) as f:\n",
    "    endpoint_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for all future calls for the query\n",
    "top_metadata = get_new_tweets(Auth,query,top_metadata,text,location,date,time)\n",
    "endpoint_metadata = boom(Auth,query,endpoint_metadata,text,location,date,time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
